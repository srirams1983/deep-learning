{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    },
    "colab": {
      "name": "dlnd_image_classification.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "woaQzCU4smj8"
      },
      "source": [
        "# Image Classification\n",
        "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
        "## Get the Data\n",
        "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iythrj3CtJ-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf38faba-5189-4397-dad6-657948c1f677"
      },
      "source": [
        "\n",
        "import tarfile\n",
        "import pickle\n",
        "import random\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "from urllib.request import urlretrieve\n",
        "from os.path import isfile, isdir\n",
        "from tqdm import tqdm\n",
        "\n",
        "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
        "\n",
        "class DownloadProgress(tqdm):\n",
        "    last_block = 0\n",
        "\n",
        "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
        "        self.total = total_size\n",
        "        self.update((block_num - self.last_block) * block_size)\n",
        "        self.last_block = block_num\n",
        "\n",
        "\"\"\"\n",
        "    check if the data (zip) file is already downloaded\n",
        "    if not, download it from \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\" and save as cifar-10-python.tar.gz\n",
        "\"\"\"\n",
        "\n",
        "def load_label_names():\n",
        "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "def load_cfar10_batch(cifar10_dataset_folder_path, batch_id):\n",
        "    with open(cifar10_dataset_folder_path + '/data_batch_' + str(batch_id), mode='rb') as file:\n",
        "        # note the encoding type is 'latin1'\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    labels = batch['labels']\n",
        "\n",
        "    return features, labels\n",
        "\n",
        "def batch_features_labels(features, labels, batch_size):\n",
        "    \"\"\"\n",
        "    Split features and labels into batches\n",
        "    \"\"\"\n",
        "    for start in range(0, len(features), batch_size):\n",
        "        end = min(start + batch_size, len(features))\n",
        "        yield features[start:end], labels[start:end]\n",
        "\n",
        "def load_preprocess_training_batch(batch_id, batch_size):\n",
        "    \"\"\"\n",
        "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
        "    \"\"\"\n",
        "    filename = 'preprocess_batch_' + str(batch_id) + '.p'\n",
        "    features, labels = pickle.load(open(filename, mode='rb'))\n",
        "\n",
        "    # Return the training data in batches of size <batch_size> or less\n",
        "    return batch_features_labels(features, labels, batch_size)\n",
        "\n",
        "def display_stats(cifar10_dataset_folder_path, batch_id, sample_id):\n",
        "    features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_id)\n",
        "\n",
        "    if not (0 <= sample_id < len(features)):\n",
        "        print('{} samples in batch {}.  {} is out of range.'.format(len(features), batch_id, sample_id))\n",
        "        return None\n",
        "\n",
        "    print('\\nStats of batch #{}:'.format(batch_id))\n",
        "    print('# of Samples: {}\\n'.format(len(features)))\n",
        "\n",
        "    label_names = load_label_names()\n",
        "    label_counts = dict(zip(*np.unique(labels, return_counts=True)))\n",
        "    for key, value in label_counts.items():\n",
        "        print('Label Counts of [{}]({}) : {}'.format(key, label_names[key].upper(), value))\n",
        "\n",
        "    sample_image = features[sample_id]\n",
        "    sample_label = labels[sample_id]\n",
        "\n",
        "    print('\\nExample of Image {}:'.format(sample_id))\n",
        "    print('Image - Min Value: {} Max Value: {}'.format(sample_image.min(), sample_image.max()))\n",
        "    print('Image - Shape: {}'.format(sample_image.shape))\n",
        "    print('Label - Label Id: {} Name: {}'.format(sample_label, label_names[sample_label]))\n",
        "\n",
        "def normalize(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: input image data in numpy array [32, 32, 3]\n",
        "        return\n",
        "            - normalized x\n",
        "    \"\"\"\n",
        "    min_val = np.min(x)\n",
        "    max_val = np.max(x)\n",
        "    x = (x-min_val) / (max_val-min_val)\n",
        "    return x\n",
        "\n",
        "def one_hot_encode(x):\n",
        "    \"\"\"\n",
        "        argument\n",
        "            - x: a list of labels\n",
        "        return\n",
        "            - one hot encoding matrix (number of labels, number of class)\n",
        "    \"\"\"\n",
        "    encoded = np.zeros((len(x), 10))\n",
        "\n",
        "    for idx, val in enumerate(x):\n",
        "        encoded[idx][val] = 1\n",
        "\n",
        "    return encoded\n",
        "\n",
        "def _preprocess_and_save(normalize, one_hot_encode, features, labels, filename):\n",
        "    features = normalize(features)\n",
        "    labels = one_hot_encode(labels)\n",
        "\n",
        "    pickle.dump((features, labels), open(filename, 'wb'))\n",
        "\n",
        "def preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode):\n",
        "    n_batches = 5\n",
        "    valid_features = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for batch_i in range(1, n_batches + 1):\n",
        "        features, labels = load_cfar10_batch(cifar10_dataset_folder_path, batch_i)\n",
        "\n",
        "        # find index to be the point as validation data in the whole dataset of the batch (10%)\n",
        "        index_of_validation = int(len(features) * 0.1)\n",
        "\n",
        "        # preprocess the 90% of the whole dataset of the batch\n",
        "        # - normalize the features\n",
        "        # - one_hot_encode the lables\n",
        "        # - save in a new file named, \"preprocess_batch_\" + batch_number\n",
        "        # - each file for each batch\n",
        "        _preprocess_and_save(normalize, one_hot_encode,\n",
        "                             features[:-index_of_validation], labels[:-index_of_validation],\n",
        "                             'preprocess_batch_' + str(batch_i) + '.p')\n",
        "\n",
        "        # unlike the training dataset, validation dataset will be added through all batch dataset\n",
        "        # - take 10% of the whold dataset of the batch\n",
        "        # - add them into a list of\n",
        "        #   - valid_features\n",
        "        #   - valid_labels\n",
        "        valid_features.extend(features[-index_of_validation:])\n",
        "        valid_labels.extend(labels[-index_of_validation:])\n",
        "\n",
        "    # preprocess the all stacked validation dataset\n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(valid_features), np.array(valid_labels),\n",
        "                         'preprocess_validation.p')\n",
        "\n",
        "    # load the test dataset\n",
        "    with open(cifar10_dataset_folder_path + '/test_batch', mode='rb') as file:\n",
        "        batch = pickle.load(file, encoding='latin1')\n",
        "\n",
        "    # preprocess the testing data\n",
        "    test_features = batch['data'].reshape((len(batch['data']), 3, 32, 32)).transpose(0, 2, 3, 1)\n",
        "    test_labels = batch['labels']\n",
        "\n",
        "    # Preprocess and Save all testing data\n",
        "    _preprocess_and_save(normalize, one_hot_encode,\n",
        "                         np.array(test_features), np.array(test_labels),\n",
        "                         'preprocess_training.p')\n",
        "\n",
        "def conv_net(x, keep_prob):\n",
        "    conv1_filter = tf.Variable(tf.random.truncated_normal(shape=[3, 3, 3, 64], mean=0, stddev=0.08))\n",
        "    conv2_filter = tf.Variable(tf.random.truncated_normal(shape=[3, 3, 64, 128], mean=0, stddev=0.08))\n",
        "    conv3_filter = tf.Variable(tf.random.truncated_normal(shape=[5, 5, 128, 256], mean=0, stddev=0.08))\n",
        "    conv4_filter = tf.Variable(tf.random.truncated_normal(shape=[5, 5, 256, 512], mean=0, stddev=0.08))\n",
        "\n",
        "    # 1, 2\n",
        "    conv1 = tf.nn.conv2d(x, conv1_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv1 = tf.nn.relu(conv1)\n",
        "    conv1_pool = tf.nn.max_pool(conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv1_bn = tf.compat.v1.layers.batch_normalization(conv1_pool)\n",
        "\n",
        "    # 3, 4\n",
        "    conv2 = tf.nn.conv2d(conv1_bn, conv2_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv2 = tf.nn.relu(conv2)\n",
        "    conv2_pool = tf.nn.max_pool(conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv2_bn = tf.compat.v1.layers.batch_normalization(conv2_pool)\n",
        "\n",
        "    # 5, 6\n",
        "    conv3 = tf.nn.conv2d(conv2_bn, conv3_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv3 = tf.nn.relu(conv3)\n",
        "    conv3_pool = tf.nn.max_pool(conv3, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv3_bn = tf.compat.v1.layers.batch_normalization(conv3_pool)\n",
        "\n",
        "    # 7, 8\n",
        "    conv4 = tf.nn.conv2d(conv3_bn, conv4_filter, strides=[1,1,1,1], padding='SAME')\n",
        "    conv4 = tf.nn.relu(conv4)\n",
        "    conv4_pool = tf.nn.max_pool(conv4, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
        "    conv4_bn = tf.compat.v1.layers.batch_normalization(conv4_pool)\n",
        "\n",
        "    # 9\n",
        "    flat = tf.compat.v1.layers.flatten(conv4_bn)\n",
        "\n",
        "    # 10\n",
        "    full1 = tf.compat.v1.layers.dense(inputs=flat, units=128, activation=tf.nn.relu)\n",
        "    full1 = tf.nn.dropout(full1, keep_prob)\n",
        "    full1 = tf.compat.v1.layers.batch_normalization(full1)\n",
        "\n",
        "    # 11\n",
        "    full2 = tf.compat.v1.layers.dense(inputs=full1, units=256, activation=tf.nn.relu)\n",
        "    full2 = tf.nn.dropout(full2, keep_prob)\n",
        "    full2 = tf.compat.v1.layers.batch_normalization(full2)\n",
        "\n",
        "    # 12\n",
        "    full3 = tf.compat.v1.layers.dense(inputs=full2, units=512, activation=tf.nn.relu)\n",
        "    full3 = tf.nn.dropout(full3, keep_prob)\n",
        "    full3 = tf.compat.v1.layers.batch_normalization(full3)\n",
        "\n",
        "    # 13\n",
        "    full4 = tf.compat.v1.layers.dense(inputs=full3, units=1024, activation=tf.nn.relu)\n",
        "    full4 = tf.nn.dropout(full4, keep_prob)\n",
        "    full4 = tf.compat.v1.layers.batch_normalization(full4)\n",
        "\n",
        "    # 14\n",
        "    out = tf.compat.v1.layers.dense(inputs=full3, units=10, activation=None)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Download the dataset (if not exist yet)\n",
        "    if not isfile('cifar-10-python.tar.gz'):\n",
        "        with DownloadProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
        "            urlretrieve(\n",
        "                'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
        "                'cifar-10-python.tar.gz',\n",
        "                pbar.hook)\n",
        "\n",
        "    if not isdir(cifar10_dataset_folder_path):\n",
        "        with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
        "            tar.extractall()\n",
        "            tar.close()\n",
        "\n",
        "    # Explore the dataset\n",
        "    batch_id = 3\n",
        "    sample_id = 7000\n",
        "    display_stats(cifar10_dataset_folder_path, batch_id, sample_id)\n",
        "\n",
        "    # Preprocess all the data and save it\n",
        "    preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)\n",
        "\n",
        "    # load the saved dataset\n",
        "    valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))\n",
        "\n",
        "    # Hyper parameters\n",
        "    epochs = 10\n",
        "    batch_size = 128\n",
        "    keep_probability = 0.7\n",
        "    learning_rate = 0.001\n",
        "\n",
        "    # Remove previous weights, bias, inputs, etc..\n",
        "    tf.compat.v1.reset_default_graph()\n",
        "\n",
        "    # Inputs\n",
        "    x = tf.compat.v1.placeholder(tf.float32, shape=(None, 32, 32, 3), name='x')\n",
        "    y =  tf.compat.v1.placeholder(tf.float32, shape=(None, 10), name='y')\n",
        "    keep_prob = tf.compat.v1.placeholder(tf.float32, name='keep_prob')\n",
        "\n",
        "    # Build model\n",
        "    logits = conv_net(x, keep_prob)\n",
        "    model = tf.identity(logits, name='logits') # Name logits Tensor, so that can be loaded from disk after training\n",
        "\n",
        "    # Loss and Optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Accuracy\n",
        "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
        "\n",
        "    # Training Phase\n",
        "    save_model_path = './image_classification'\n",
        "\n",
        "    print('Training...')\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        # Initializing the variables\n",
        "        sess.run(tf.compat.v1.global_variables_initializer())\n",
        "\n",
        "        # Training cycle\n",
        "        for epoch in range(epochs):\n",
        "            # Loop over all batches\n",
        "            n_batches = 5\n",
        "            for batch_i in range(1, n_batches + 1):\n",
        "                for batch_features, batch_labels in load_preprocess_training_batch(batch_i, batch_size):\n",
        "                    #train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
        "                    sess.run(optimizer,\n",
        "                          feed_dict={\n",
        "                          x: batch_features,\n",
        "                          y: batch_labels,\n",
        "                          keep_prob: 1\n",
        "                    })\n",
        "                print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
        "                loss = sess.run(cost,\n",
        "                    feed_dict={\n",
        "                        x: batch_features,\n",
        "                        y: batch_labels,\n",
        "                        keep_prob: 1.\n",
        "                    })\n",
        "                valid_acc = sess.run(accuracy,\n",
        "                         feed_dict={\n",
        "                             x: valid_features,\n",
        "                             y: valid_labels,\n",
        "                             keep_prob: 1.\n",
        "                         })\n",
        "                print('Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(loss, valid_acc))\n",
        "\n",
        "        # Save Model\n",
        "        saver = tf.train.Saver()\n",
        "        save_path = saver.save(sess, save_model_path)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Stats of batch #3:\n",
            "# of Samples: 10000\n",
            "\n",
            "Label Counts of [0](AIRPLANE) : 994\n",
            "Label Counts of [1](AUTOMOBILE) : 1042\n",
            "Label Counts of [2](BIRD) : 965\n",
            "Label Counts of [3](CAT) : 997\n",
            "Label Counts of [4](DEER) : 990\n",
            "Label Counts of [5](DOG) : 1029\n",
            "Label Counts of [6](FROG) : 978\n",
            "Label Counts of [7](HORSE) : 1015\n",
            "Label Counts of [8](SHIP) : 961\n",
            "Label Counts of [9](TRUCK) : 1029\n",
            "\n",
            "Example of Image 7000:\n",
            "Image - Min Value: 24 Max Value: 252\n",
            "Image - Shape: (32, 32, 3)\n",
            "Label - Label Id: 0 Name: airplane\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/normalization.py:308: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
            "  '`tf.layers.batch_normalization` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1719: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:329: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training...\n",
            "Epoch  1, CIFAR-10 Batch 1:  Loss:     1.9112 Validation Accuracy: 0.319800\n",
            "Epoch  1, CIFAR-10 Batch 2:  Loss:     1.4022 Validation Accuracy: 0.460000\n",
            "Epoch  1, CIFAR-10 Batch 3:  Loss:     0.8634 Validation Accuracy: 0.523600\n",
            "Epoch  1, CIFAR-10 Batch 4:  Loss:     1.0742 Validation Accuracy: 0.573000\n",
            "Epoch  1, CIFAR-10 Batch 5:  Loss:     0.8410 Validation Accuracy: 0.612400\n",
            "Epoch  2, CIFAR-10 Batch 1:  Loss:     0.8499 Validation Accuracy: 0.639200\n",
            "Epoch  2, CIFAR-10 Batch 2:  Loss:     0.6770 Validation Accuracy: 0.642600\n",
            "Epoch  2, CIFAR-10 Batch 3:  Loss:     0.3401 Validation Accuracy: 0.667400\n",
            "Epoch  2, CIFAR-10 Batch 4:  Loss:     0.4734 Validation Accuracy: 0.692200\n",
            "Epoch  2, CIFAR-10 Batch 5:  Loss:     0.2627 Validation Accuracy: 0.689200\n",
            "Epoch  3, CIFAR-10 Batch 1:  Loss:     0.5259 Validation Accuracy: 0.684200\n",
            "Epoch  3, CIFAR-10 Batch 2:  Loss:     0.2718 Validation Accuracy: 0.694800\n",
            "Epoch  3, CIFAR-10 Batch 3:  Loss:     0.1794 Validation Accuracy: 0.706600\n",
            "Epoch  3, CIFAR-10 Batch 4:  Loss:     0.1678 Validation Accuracy: 0.692400\n",
            "Epoch  3, CIFAR-10 Batch 5:  Loss:     0.0719 Validation Accuracy: 0.699400\n",
            "Epoch  4, CIFAR-10 Batch 1:  Loss:     0.2049 Validation Accuracy: 0.680400\n",
            "Epoch  4, CIFAR-10 Batch 2:  Loss:     0.1006 Validation Accuracy: 0.685600\n",
            "Epoch  4, CIFAR-10 Batch 3:  Loss:     0.1002 Validation Accuracy: 0.650000\n",
            "Epoch  4, CIFAR-10 Batch 4:  Loss:     0.0454 Validation Accuracy: 0.697800\n",
            "Epoch  4, CIFAR-10 Batch 5:  Loss:     0.0447 Validation Accuracy: 0.682400\n",
            "Epoch  5, CIFAR-10 Batch 1:  Loss:     0.0418 Validation Accuracy: 0.682200\n",
            "Epoch  5, CIFAR-10 Batch 2:  Loss:     0.0403 Validation Accuracy: 0.695400\n",
            "Epoch  5, CIFAR-10 Batch 3:  Loss:     0.0273 Validation Accuracy: 0.682800\n",
            "Epoch  5, CIFAR-10 Batch 4:  Loss:     0.0231 Validation Accuracy: 0.691400\n",
            "Epoch  5, CIFAR-10 Batch 5:  Loss:     0.0193 Validation Accuracy: 0.716400\n",
            "Epoch  6, CIFAR-10 Batch 1:  Loss:     0.0111 Validation Accuracy: 0.713200\n",
            "Epoch  6, CIFAR-10 Batch 2:  Loss:     0.0274 Validation Accuracy: 0.712000\n",
            "Epoch  6, CIFAR-10 Batch 3:  Loss:     0.0278 Validation Accuracy: 0.692400\n",
            "Epoch  6, CIFAR-10 Batch 4:  Loss:     0.0112 Validation Accuracy: 0.707800\n",
            "Epoch  6, CIFAR-10 Batch 5:  Loss:     0.0088 Validation Accuracy: 0.717000\n",
            "Epoch  7, CIFAR-10 Batch 1:  Loss:     0.0220 Validation Accuracy: 0.692200\n",
            "Epoch  7, CIFAR-10 Batch 2:  Loss:     0.0133 Validation Accuracy: 0.703600\n",
            "Epoch  7, CIFAR-10 Batch 3:  Loss:     0.0039 Validation Accuracy: 0.701600\n",
            "Epoch  7, CIFAR-10 Batch 4:  Loss:     0.0076 Validation Accuracy: 0.712400\n",
            "Epoch  7, CIFAR-10 Batch 5:  Loss:     0.0039 Validation Accuracy: 0.710800\n",
            "Epoch  8, CIFAR-10 Batch 1:  Loss:     0.0076 Validation Accuracy: 0.727000\n",
            "Epoch  8, CIFAR-10 Batch 2:  Loss:     0.0067 Validation Accuracy: 0.702600\n",
            "Epoch  8, CIFAR-10 Batch 3:  Loss:     0.0038 Validation Accuracy: 0.697400\n",
            "Epoch  8, CIFAR-10 Batch 4:  Loss:     0.0037 Validation Accuracy: 0.734600\n",
            "Epoch  8, CIFAR-10 Batch 5:  Loss:     0.0094 Validation Accuracy: 0.709200\n",
            "Epoch  9, CIFAR-10 Batch 1:  Loss:     0.0057 Validation Accuracy: 0.737200\n",
            "Epoch  9, CIFAR-10 Batch 2:  Loss:     0.0010 Validation Accuracy: 0.730800\n",
            "Epoch  9, CIFAR-10 Batch 3:  Loss:     0.0022 Validation Accuracy: 0.726200\n",
            "Epoch  9, CIFAR-10 Batch 4:  Loss:     0.0024 Validation Accuracy: 0.727400\n",
            "Epoch  9, CIFAR-10 Batch 5:  Loss:     0.0046 Validation Accuracy: 0.722600\n",
            "Epoch 10, CIFAR-10 Batch 1:  "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TU0wflGIsmlr"
      },
      "source": [
        "## Why 50-80% Accuracy?\n",
        "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 80%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
        "## Submitting This Project\n",
        "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
      ]
    }
  ]
}